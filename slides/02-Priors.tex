\section{Priors}

\subsection{Recommended References}
\begin{frame}{Priors and Posteriors - Recommended References}
	\begin{vfilleditems}
		\item \textcite{gelman2013bayesian}:
		\begin{vfilleditems}
			\item Chapter 2: Single-parameter models
			\item Chapter 3: Introduction to multiparameter models
		\end{vfilleditems}
		\item \textcite{mcelreath2020statistical} - Chapter 4: Geocentric Models
		\item \textcite{gelman2020regression}:
		\begin{vfilleditems}
			\item Chapter 9, Section 9.3: Prior information and Bayesian synthesis
			\item Chapter 9, Section 9.5: Uniform, weakly informative, and informative priors in regression
		\end{vfilleditems}
		\item \textcite{vandeschootBayesianStatisticsModelling2021}
	\end{vfilleditems}
\end{frame}

\begin{frame}{Prior Probability }
	Bayesian statistics is characterized by the use of prior information
	as the prior probability $P(\theta)$, often just prior:
	$$
		\underbrace{P(\theta \mid y)}_{\text{Posterior}} = \frac{\overbrace{P(y \mid  \theta)}^{\text{Likelihood}} \cdot \overbrace{P(\theta)}^{\text{Prior}}}{\underbrace{P(y)}_{\text{Normalizing Constant}}}
	$$
\end{frame}

\subsection{The subjectivity of the Prior}
\begin{frame}{The subjectivity of the Prior}
	\begin{vfilleditems}
		\item Many critics to Bayesian statistics are due the subjectivity
		in eliciting priors probability on certain hypothesis or model parameter's
		values.
		\item Subjectivity is something unwanted in the ideal picture of the
		scientist and the scientific method.
		\item Anything that involves human action will never be free from
		subjectivity.
		We have subjectivity in everything and science is \textcolor{red}{no} exception.
		\item The creative and deductive process of theory and hypotheses formulations
		is \textbf{not} objective.
		\item Frequentist statistics, which bans the use of prior probabilities
		is also subjective, since there is \textbf{A LOT} of subjectivity in
		choosing which model and likelihood function \parencite{jaynesProbabilityTheoryLogic2003, vandeschootBayesianStatisticsModelling2021}
	\end{vfilleditems}
\end{frame}

\begin{frame}{How to Incorporate Subjectivity}
	\begin{vfilleditems}
		\item Bayesian statistics \textbf{embraces} subjectivity while
		frequentist statistics \textbf{bans} it.
		\item For Bayesian statistics, \textbf{subjectivity guides our inferences}
		and leads to more robust and reliable models that can assist in
		decision making.
		\item Whereas, for frequentist statistics, \textbf{subjectivity is a taboo}
		and all inferences should be objective,
		even if it resorts to \textbf{hiding and omitting model assumptions}.
		\item Bayesian statistics also has assumptions and subjectivity,
		but these are \textbf{declared and formalized}
	\end{vfilleditems}
\end{frame}

\subsection{Types of Priors}

\begin{frame}{Types of Priors}
	In general, we can have 3 types of priors in a Bayesian approach
	\parencite{gelman2013bayesian, mcelreath2020statistical, vandeschootBayesianStatisticsModelling2021}:
	\begin{vfilleditems}
		\item \textbf{uniform (flat)}: not recommended.
		\item \textbf{weakly informative}: small amounts of real-world information
		along with common sense and low specific domain knowledge added.
		\item \textbf{informative}: introduction of medium to high domain knowledge.
	\end{vfilleditems}
\end{frame}

\subsubsection{Uniform Prior (Flat)}
\begin{frame}{Uniform Prior (Flat)}
	Starts from the premise that ``everything is possible''.
	There is no limits in the degree of beliefs that the distribution of certain
	values must be or any sort of restrictions.
	\vfill
	Flat and super-vague priors are not usually recommended and some thought
	should included to have at least weakly informative priors.
	\vfill
	Formally, an uniform prior is an uniform distribution over all the
	possible support of the possible values:
	\begin{vfilleditems}
		\item \textbf{model parameters}: $\{\theta \in \mathbb{R} : -\infty < \theta < \infty\}$
		\item \textbf{model error or residuals}: $\{\sigma \in \mathbb{R}^+ : 0 \leq \theta < \infty\}$
	\end{vfilleditems}
\end{frame}

\subsubsection{Weekly Informative Prior}
\begin{frame}{Weekly Informative Prior}
	Here we start to have ``educated'' guess about our parameter values.
	Hence, we don't start from the premise that ``anything is possible''.
	\vfill
	I recommend always to transform the priors of the problem at hand into
	something centered in $0$ with standard deviation of $1$\footnote{
		this is called standardization,
		transforming all variables into $\mu=0$ and $\sigma=1$.}:
	\vfill
	\begin{vfilleditems}
		\item $\theta \sim \text{Normal}(0, 1)$ (Andrew Gelman's preferred choice\footnote{
			see more about prior choices in the
			\href{https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations}{\texttt{Stan}'s GitHub wiki}.})
		\item $\theta \sim \text{Student}(\nu=3, 0, 1)$ (Aki Vehtari's preferred choice)
	\end{vfilleditems}
\end{frame}
